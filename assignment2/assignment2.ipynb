{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Fudan PRML 23Spring Assignment2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>*Your Name, Student ID and Date: [Name], [Student ID], [Date]*</font>\n",
    "\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red' size = 3> *DDL: 2023.06.11 23:59* </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. FDUNN: your toy torch-like deep learning library (60 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will fist implement your own torch-like deep learning library with `numpy`, named `fdunn`.\n",
    "\n",
    "PyTorch: [Link](https://pytorch.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# setup code, auto reload your .py file\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# numpy\n",
    "import numpy as np\n",
    "np.random.seed(233)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to impletement several standard deep neural modelwork modules in the `./fdunn` folder:\n",
    "1.   linear/conv/pooling\n",
    "2.   activation\n",
    "3.   loss\n",
    "4.   optim\n",
    "5.   trainer\n",
    "\n",
    "We have written most of the code for you already, and you only need to fill in the most essential parts. We have also prepared several test cases for you to check if your code works correctly.\n",
    "\n",
    "Furthermore, you can also test the accuracy of your code by comparing its output with the output of sk-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\Life_Dancer\\Desktop\\PRML-Spring23-FDU\\assignment2\\fdunn')\n",
    "\n",
    "from fdunn import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get dataset MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fdunn.data.data_loader import get_dataset\n",
    "\n",
    "dataset = 'MNIST'\n",
    "trainloader, testloader = get_dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fdunn.modules.linear import Linear\n",
    "from fdunn.modules.activation import Sigmoid\n",
    "from fdunn.modules.loss import BCELoss, CrossEntropyLoss\n",
    "from fdunn.optim.sgd import SGD\n",
    "\n",
    "class FNN:\n",
    "    def __init__(self, in_features, hidden_sizes, num_classes):\n",
    "        self.linear1 = Linear(in_features, hidden_sizes[0])\n",
    "        self.sigmoid = Sigmoid()\n",
    "        self.hidden_layers = []\n",
    "        for i in range(len(hidden_sizes) - 1):\n",
    "            layer = Linear(hidden_sizes[i], hidden_sizes[i+1])\n",
    "            self.hidden_layers.append(layer)\n",
    "        self.linear_final = Linear(hidden_sizes[-1], num_classes)\n",
    "        self.layers = [self.linear1, self.sigmoid] + self.hidden_layers + [self.linear_final]\n",
    "    \n",
    "    def forward(self, input):\n",
    "        output = self.linear1.forward(input)\n",
    "        output = self.sigmoid.forward(output)\n",
    "        for layer in self.hidden_layers:\n",
    "            output = layer.forward(output)\n",
    "            output = self.sigmoid.forward(output)\n",
    "        output = self.linear_final.forward(output)\n",
    "        return output\n",
    "    \n",
    "    def backward(self, output_grad):\n",
    "        output_grad = self.linear_final.backward(output_grad)\n",
    "        for layer in reversed(self.hidden_layers):\n",
    "            output_grad = self.sigmoid.backward(output_grad)\n",
    "            output_grad = layer.backward(output_grad)\n",
    "        output_grad = self.sigmoid.backward(output_grad)\n",
    "        output_grad = self.linear1.backward(output_grad)\n",
    "        return output_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init: W.shape=(64, 784), b.shape=(64,)\n",
      "init: W.shape=(64, 64), b.shape=(64,)\n",
      "init: W.shape=(10, 64), b.shape=(10,)\n"
     ]
    }
   ],
   "source": [
    "in_features = 784\n",
    "hidden_sizes = [64, 64] \n",
    "num_classes = 10\n",
    "\n",
    "model = FNN(in_features, hidden_sizes, num_classes)\n",
    "criterion = BCELoss(model)\n",
    "\n",
    "lr = 1e-7\n",
    "optimizer = SGD(model, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def epoch(mode, dataloader, model, optimizer, criterion):\n",
    "    loss_avg, acc_avg, num_exp = 0, 0, 0\n",
    "\n",
    "    for i_batch, datum in enumerate(dataloader):\n",
    "        img = datum[0]\n",
    "        lab = datum[1]\n",
    "\n",
    "        n_b = lab.shape[0]\n",
    "        truth = lab\n",
    "\n",
    "        output = model.forward(img)\n",
    "\n",
    "        lab = F.one_hot(lab, 10)\n",
    "        lab = lab.numpy()\n",
    "\n",
    "        loss = criterion.forward(output, lab)\n",
    "        predicted = np.argmax(output, 1)\n",
    "\n",
    "        correct = (predicted == truth.numpy()).sum()\n",
    "\n",
    "        loss_avg += loss.item()*n_b\n",
    "        acc_avg += correct.item()\n",
    "        num_exp += n_b\n",
    "\n",
    "        if mode == 'train':\n",
    "            criterion.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        # print(f\"Batch: {i_batch}, Loss: {loss.item()}, Accuracy: {correct.item() / n_b}\")\n",
    "\n",
    "    loss_avg /= num_exp\n",
    "    acc_avg /= num_exp\n",
    "\n",
    "    return loss_avg, acc_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tReal Acc: 0.11236666666666667\tTest Acc: 0.1135\n",
      "Epoch: 1\tReal Acc: 0.11236666666666667\tTest Acc: 0.1135\n",
      "Epoch: 2\tReal Acc: 0.11236666666666667\tTest Acc: 0.1136\n",
      "Epoch: 3\tReal Acc: 0.11275\tTest Acc: 0.1141\n",
      "Epoch: 4\tReal Acc: 0.11473333333333334\tTest Acc: 0.116\n",
      "Epoch: 5\tReal Acc: 0.11715\tTest Acc: 0.1183\n",
      "Epoch: 6\tReal Acc: 0.11923333333333333\tTest Acc: 0.1201\n",
      "Epoch: 7\tReal Acc: 0.1207\tTest Acc: 0.1206\n",
      "Epoch: 8\tReal Acc: 0.12156666666666667\tTest Acc: 0.1206\n",
      "Epoch: 9\tReal Acc: 0.1219\tTest Acc: 0.1212\n",
      "Epoch: 10\tReal Acc: 0.1219\tTest Acc: 0.1221\n",
      "Epoch: 11\tReal Acc: 0.12358333333333334\tTest Acc: 0.1221\n",
      "Epoch: 12\tReal Acc: 0.12346666666666667\tTest Acc: 0.122\n",
      "Epoch: 13\tReal Acc: 0.12353333333333333\tTest Acc: 0.122\n",
      "Epoch: 14\tReal Acc: 0.12346666666666667\tTest Acc: 0.122\n",
      "Epoch: 15\tReal Acc: 0.1234\tTest Acc: 0.122\n",
      "Epoch: 16\tReal Acc: 0.12355\tTest Acc: 0.122\n",
      "Epoch: 17\tReal Acc: 0.12355\tTest Acc: 0.1219\n",
      "Epoch: 18\tReal Acc: 0.1235\tTest Acc: 0.1219\n",
      "Epoch: 19\tReal Acc: 0.12353333333333333\tTest Acc: 0.1218\n"
     ]
    }
   ],
   "source": [
    "train_epochs = 20\n",
    "lr_schedule = [10, 15]\n",
    "decay = True\n",
    "\n",
    "for e in range(train_epochs):\n",
    "\n",
    "    train_loss, train_acc = epoch(\"train\", dataloader=trainloader, model=model, optimizer=optimizer, criterion=criterion)\n",
    "\n",
    "    test_loss, test_acc = epoch(\"test\", dataloader=testloader, model=model, optimizer=None, criterion=criterion)\n",
    "\n",
    "    print(\"Epoch: {}\\tReal Acc: {}\\tTest Acc: {}\".format(e, train_acc, test_acc))\n",
    "\n",
    "    if e in lr_schedule and decay:\n",
    "        lr *= 0.1\n",
    "        optimizer = SGD(model, lr=lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fdunn.modules.linear import Linear\n",
    "from fdunn.modules.activation import Sigmoid\n",
    "from fdunn.modules.loss import BCELoss, CrossEntropyLoss\n",
    "from fdunn.optim.sgd import SGD\n",
    "from fdunn.modules.conv import Conv2d\n",
    "from fdunn.modules.pooling import MaxPool2d\n",
    "\n",
    "class CNN:\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride_size, hidden_sizes, num_classes):\n",
    "        self.conv = Conv2d(in_channels, out_channels, kernel_size)\n",
    "        self.sigmoid = Sigmoid()\n",
    "        self.pool = MaxPool2d(kernel_size, stride_size)\n",
    "        self.hidden_layers = []\n",
    "        for i in range(1, len(hidden_sizes)):\n",
    "            layer = Linear(hidden_sizes[i-1], hidden_sizes[i])\n",
    "            self.hidden_layers.append(layer)\n",
    "        self.linear_final = Linear(hidden_sizes[-1], num_classes)\n",
    "        self.layers = [self.conv, self.sigmoid] + self.hidden_layers + [self.linear_final]\n",
    "    \n",
    "    def forward(self, input):\n",
    "        output = self.conv.forward(input)\n",
    "        output = self.sigmoid.forward(output)\n",
    "        output = self.pool.forward(output)\n",
    "        # print('output.shape: ', output.shape)  # 将特征图展平为向量\n",
    "        for layer in self.hidden_layers:\n",
    "            output = layer.forward(output)\n",
    "            output = self.sigmoid.forward(output)\n",
    "        output = self.linear_final.forward(output)\n",
    "        return output\n",
    "    \n",
    "    def backward(self, output_grad):\n",
    "        output_grad = self.linear_final.backward(output_grad)\n",
    "        for layer in reversed(self.hidden_layers):\n",
    "            output_grad = layer.backward(output_grad)\n",
    "            output_grad = self.sigmoid.backward(output_grad)\n",
    "        output_grad = self.pool.backward(output_grad)\n",
    "        output_grad = self.sigmoid.backward(output_grad)\n",
    "        output_grad = self.conv.backward(output_grad)\n",
    "        return output_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init: W.shape=(10, 576), b.shape=(10,)\n"
     ]
    }
   ],
   "source": [
    "in_channels = 1\n",
    "out_channels = 4\n",
    "kernel_size = 3\n",
    "stride_size = 2\n",
    "hidden_sizes = [576]  # 两个隐藏层，大小逐渐减少\n",
    "num_classes = 10\n",
    "\n",
    "model = CNN(in_channels, out_channels, kernel_size, stride_size, hidden_sizes, num_classes)\n",
    "criterion = BCELoss(model)\n",
    "\n",
    "lr = 1e-7\n",
    "optimizer = SGD(model, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def epoch(mode, dataloader, model, optimizer, criterion):\n",
    "    loss_avg, acc_avg, num_exp = 0, 0, 0\n",
    "\n",
    "    for i_batch, datum in enumerate(dataloader):\n",
    "        img = datum[0]\n",
    "        lab = datum[1]\n",
    "\n",
    "        n_b = lab.shape[0]\n",
    "        truth = lab\n",
    "\n",
    "        output = model.forward(img)\n",
    "\n",
    "        lab = F.one_hot(lab, 10)\n",
    "        lab = lab.numpy()\n",
    "\n",
    "        loss = criterion.forward(output, lab)\n",
    "        predicted = np.argmax(output, 1)\n",
    "\n",
    "        correct = (predicted == truth.numpy()).sum()\n",
    "\n",
    "        loss_avg += loss.item()*n_b\n",
    "        acc_avg += correct.item()\n",
    "        num_exp += n_b\n",
    "\n",
    "        if mode == 'train':\n",
    "            criterion.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Batch: {i_batch}, Loss: {loss.item()}, Accuracy: {correct.item() / n_b}\")\n",
    "\n",
    "    loss_avg /= num_exp\n",
    "    acc_avg /= num_exp\n",
    "\n",
    "    return loss_avg, acc_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0, Loss: 0.7212353715629498, Accuracy: 0.125\n",
      "Batch: 1, Loss: 0.6967853556378223, Accuracy: 0.1875\n",
      "Batch: 2, Loss: 0.7047886567656144, Accuracy: 0.15625\n",
      "Batch: 3, Loss: 0.7049310861545516, Accuracy: 0.140625\n",
      "Batch: 4, Loss: 0.7040385231962347, Accuracy: 0.171875\n",
      "Batch: 5, Loss: 0.6850737349302332, Accuracy: 0.203125\n",
      "Batch: 6, Loss: 0.6871274885770369, Accuracy: 0.1328125\n",
      "Batch: 7, Loss: 0.6787056250731768, Accuracy: 0.1875\n",
      "Batch: 8, Loss: 0.6878268940277004, Accuracy: 0.1328125\n",
      "Batch: 9, Loss: 0.6694310932888916, Accuracy: 0.2109375\n",
      "Batch: 10, Loss: 0.6733723068972125, Accuracy: 0.171875\n",
      "Batch: 11, Loss: 0.66884048137513, Accuracy: 0.2109375\n",
      "Batch: 12, Loss: 0.6697977603948073, Accuracy: 0.140625\n",
      "Batch: 13, Loss: 0.675627156495503, Accuracy: 0.1796875\n",
      "Batch: 14, Loss: 0.6727670802753571, Accuracy: 0.1640625\n",
      "Batch: 15, Loss: 0.675291125915819, Accuracy: 0.1171875\n",
      "Batch: 16, Loss: 0.6704639261693701, Accuracy: 0.140625\n",
      "Batch: 17, Loss: 0.6671598816800476, Accuracy: 0.1640625\n",
      "Batch: 18, Loss: 0.6622292908317489, Accuracy: 0.1796875\n",
      "Batch: 19, Loss: 0.6583832988465561, Accuracy: 0.203125\n",
      "Batch: 20, Loss: 0.6522795333597857, Accuracy: 0.203125\n",
      "Batch: 21, Loss: 0.6558081897187354, Accuracy: 0.1484375\n",
      "Batch: 22, Loss: 0.6542156331981879, Accuracy: 0.1640625\n",
      "Batch: 23, Loss: 0.6463132868058641, Accuracy: 0.1640625\n",
      "Batch: 24, Loss: 0.6371951743202123, Accuracy: 0.1484375\n",
      "Batch: 25, Loss: 0.6483452693969609, Accuracy: 0.1484375\n",
      "Batch: 26, Loss: 0.6536585691444381, Accuracy: 0.1484375\n",
      "Batch: 27, Loss: 0.6399438126284686, Accuracy: 0.171875\n",
      "Batch: 28, Loss: 0.6352383279805919, Accuracy: 0.1953125\n",
      "Batch: 29, Loss: 0.6418308331263762, Accuracy: 0.1796875\n",
      "Batch: 30, Loss: 0.6340681837183514, Accuracy: 0.171875\n",
      "Batch: 31, Loss: 0.6316045476267655, Accuracy: 0.15625\n",
      "Batch: 32, Loss: 0.6338665123369418, Accuracy: 0.1171875\n",
      "Batch: 33, Loss: 0.6174168365237549, Accuracy: 0.2109375\n",
      "Batch: 34, Loss: 0.625664781078827, Accuracy: 0.2109375\n",
      "Batch: 35, Loss: 0.6254132105673677, Accuracy: 0.1796875\n",
      "Batch: 36, Loss: 0.6269240058271153, Accuracy: 0.15625\n",
      "Batch: 37, Loss: 0.6145779984001346, Accuracy: 0.15625\n",
      "Batch: 38, Loss: 0.6110058080271618, Accuracy: 0.15625\n",
      "Batch: 39, Loss: 0.6146903418468626, Accuracy: 0.1796875\n",
      "Batch: 40, Loss: 0.618630755333689, Accuracy: 0.1640625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Life_Dancer\\Desktop\\PRML\\assignment2\\assignment2.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Life_Dancer/Desktop/PRML/assignment2/assignment2.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m decay \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Life_Dancer/Desktop/PRML/assignment2/assignment2.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(train_epochs):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Life_Dancer/Desktop/PRML/assignment2/assignment2.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     train_loss, train_acc \u001b[39m=\u001b[39m epoch(\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m, dataloader\u001b[39m=\u001b[39;49mtrainloader, model\u001b[39m=\u001b[39;49mmodel, optimizer\u001b[39m=\u001b[39;49moptimizer, criterion\u001b[39m=\u001b[39;49mcriterion)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Life_Dancer/Desktop/PRML/assignment2/assignment2.ipynb#X21sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     test_loss, test_acc \u001b[39m=\u001b[39m epoch(\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, dataloader\u001b[39m=\u001b[39mtestloader, model\u001b[39m=\u001b[39mmodel, optimizer\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, criterion\u001b[39m=\u001b[39mcriterion)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Life_Dancer/Desktop/PRML/assignment2/assignment2.ipynb#X21sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39mReal Acc: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39mTest Acc: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(e, train_acc, test_acc))\n",
      "\u001b[1;32mc:\\Users\\Life_Dancer\\Desktop\\PRML\\assignment2\\assignment2.ipynb Cell 22\u001b[0m in \u001b[0;36mepoch\u001b[1;34m(mode, dataloader, model, optimizer, criterion)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Life_Dancer/Desktop/PRML/assignment2/assignment2.ipynb#X21sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m num_exp \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m n_b\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Life_Dancer/Desktop/PRML/assignment2/assignment2.ipynb#X21sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Life_Dancer/Desktop/PRML/assignment2/assignment2.ipynb#X21sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     criterion\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Life_Dancer/Desktop/PRML/assignment2/assignment2.ipynb#X21sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Life_Dancer/Desktop/PRML/assignment2/assignment2.ipynb#X21sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBatch: \u001b[39m\u001b[39m{\u001b[39;00mi_batch\u001b[39m}\u001b[39;00m\u001b[39m, Loss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m.\u001b[39mitem()\u001b[39m}\u001b[39;00m\u001b[39m, Accuracy: \u001b[39m\u001b[39m{\u001b[39;00mcorrect\u001b[39m.\u001b[39mitem() \u001b[39m/\u001b[39m n_b\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Life_Dancer\\Desktop\\PRML\\assignment2\\fdunn\\modules\\loss.py:56\u001b[0m, in \u001b[0;36mBCELoss.backward\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     53\u001b[0m input_grad \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget) \u001b[39m/\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput) \u001b[39m+\u001b[39m \u001b[39m1e-7\u001b[39m)\n\u001b[0;32m     55\u001b[0m \u001b[39m# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mbackward(input_grad)\n",
      "\u001b[1;32mc:\\Users\\Life_Dancer\\Desktop\\PRML\\assignment2\\assignment2.ipynb Cell 22\u001b[0m in \u001b[0;36mCNN.backward\u001b[1;34m(self, output_grad)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Life_Dancer/Desktop/PRML/assignment2/assignment2.ipynb#X21sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m output_grad \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool\u001b[39m.\u001b[39mbackward(output_grad)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Life_Dancer/Desktop/PRML/assignment2/assignment2.ipynb#X21sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m output_grad \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msigmoid\u001b[39m.\u001b[39mbackward(output_grad)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Life_Dancer/Desktop/PRML/assignment2/assignment2.ipynb#X21sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m output_grad \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv\u001b[39m.\u001b[39;49mbackward(output_grad)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Life_Dancer/Desktop/PRML/assignment2/assignment2.ipynb#X21sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mreturn\u001b[39;00m output_grad\n",
      "File \u001b[1;32mc:\\Users\\Life_Dancer\\Desktop\\PRML\\assignment2\\fdunn\\modules\\conv.py:157\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(self, output_grad)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m# Compute bias gradients if enabled\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 157\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrads[\u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(output_grad, axis\u001b[39m=\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m))\n\u001b[0;32m    159\u001b[0m \u001b[39m# Remove padding from input gradients\u001b[39;00m\n\u001b[0;32m    160\u001b[0m input_grad \u001b[39m=\u001b[39m input_grad[:, :, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding:\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding:\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_epochs = 20\n",
    "lr_schedule = [10, 15]\n",
    "decay = True\n",
    "\n",
    "for e in range(train_epochs):\n",
    "\n",
    "    train_loss, train_acc = epoch(\"train\", dataloader=trainloader, model=model, optimizer=optimizer, criterion=criterion)\n",
    "\n",
    "    test_loss, test_acc = epoch(\"test\", dataloader=testloader, model=model, optimizer=None, criterion=criterion)\n",
    "\n",
    "    print(\"Epoch: {}\\tReal Acc: {}\\tTest Acc: {}\".format(e, train_acc, test_acc))\n",
    "\n",
    "    if e in lr_schedule and decay:\n",
    "        lr *= 0.1\n",
    "        optimizer = SGD(model, lr=lr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "44bc79bdedc951859a4620ce4f5a740abfa1bf27d20da6af0e4010c444744bef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
