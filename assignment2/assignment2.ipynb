{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Fudan PRML 23Spring Assignment2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>*Your Name, Student ID and Date: [Name], [Student ID], [Date]*</font>\n",
    "\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red' size = 3> *DDL: 2023.06.11 23:59* </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. FDUNN: your toy torch-like deep learning library (60 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will fist implement your own torch-like deep learning library with `numpy`, named `fdunn`.\n",
    "\n",
    "PyTorch: [Link](https://pytorch.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# setup code, auto reload your .py file\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# numpy\n",
    "import numpy as np\n",
    "np.random.seed(233)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to impletement several standard deep neural modelwork modules in the `./fdunn` folder:\n",
    "1.   linear/conv/pooling\n",
    "2.   activation\n",
    "3.   loss\n",
    "4.   optim\n",
    "5.   trainer\n",
    "\n",
    "We have written most of the code for you already, and you only need to fill in the most essential parts. We have also prepared several test cases for you to check if your code works correctly.\n",
    "\n",
    "Furthermore, you can also test the accuracy of your code by comparing its output with the output of sk-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\Life_Dancer\\Desktop\\PRML-Spring23-FDU\\assignment2\\fdunn')\n",
    "\n",
    "from fdunn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fdunn.modules.linear import Linear\n",
    "from fdunn.modules.activation import Sigmoid\n",
    "from fdunn.modules.loss import BCELoss, CrossEntropyLoss\n",
    "from fdunn.optim.sgd import SGD\n",
    "\n",
    "class FNN:\n",
    "    def __init__(self, in_features, hidden_size, num_classes):\n",
    "        self.linear1 = Linear(in_features, hidden_size)\n",
    "        self.sigmoid = Sigmoid()\n",
    "        self.linear2 = Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        output = self.linear1.forward(input)\n",
    "        output = self.sigmoid.forward(output)\n",
    "        output = self.linear2.forward(output)\n",
    "        return output\n",
    "    \n",
    "    def backward(self, output_grad):\n",
    "        output_grad = self.linear2.backward(output_grad)\n",
    "        output_grad = self.sigmoid.backward(output_grad)\n",
    "        output_grad = self.linear1.backward(output_grad)\n",
    "        return output_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FNN(784, 128, 10)\n",
    "criterion = CrossEntropyLoss(model)\n",
    "\n",
    "lr = 0.01\n",
    "optimizer = SGD(model, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fdunn.data.data_loader import get_dataset\n",
    "\n",
    "dataset = 'MNIST'\n",
    "trainloader, testloader = get_dataset('MNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch(mode, dataloader, model, optimizer, criterion):\n",
    "    loss_avg, acc_avg, num_exp = 0, 0, 0\n",
    "\n",
    "    for i_batch, datum in enumerate(dataloader):\n",
    "        img = datum[0]\n",
    "        lab = datum[1]\n",
    "\n",
    "        n_b = lab.shape[0]\n",
    "\n",
    "        output = model.forward(img)\n",
    "        # print(output)\n",
    "        loss = criterion.forward(output, lab)\n",
    "\n",
    "        predicted = np.argmax(output, 1)\n",
    "        correct = (predicted == lab).sum()\n",
    "\n",
    "        loss_avg += loss.item()*n_b\n",
    "        acc_avg += correct.item()\n",
    "        num_exp += n_b\n",
    "\n",
    "        if mode == 'train':\n",
    "            # optimizer.zero_grad() should we implement zero_grad()?\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    loss_avg /= num_exp\n",
    "    acc_avg /= num_exp\n",
    "\n",
    "    return loss_avg, acc_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"assignment2.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 28, 28])\n",
      "784\n",
      "torch.Size([8, 784])\n",
      "(128, 784)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# wandb.init(sync_tensorboard=False,\n",
    "#         entity='tongchen',\n",
    "#         project=\"PRML\",\n",
    "#         name='{}-{}-{}-{}'.format(dataset, model, lr, criterion)\n",
    "#     )\n",
    "\n",
    "train_epochs = 20\n",
    "lr_schedule = [10, 15]\n",
    "decay = True\n",
    "\n",
    "for e in range(train_epochs):\n",
    "\n",
    "    train_loss, train_acc = epoch(\"train\", dataloader=trainloader, model=model, optimizer=optimizer, criterion=criterion)\n",
    "\n",
    "    test_loss, test_acc = epoch(\"test\", dataloader=testloader, model=model, optimizer=None, criterion=criterion)\n",
    "\n",
    "    print(\"Epoch: {}\\tReal Acc: {}\\tTest Acc: {}\".format(e, train_acc, test_acc))\n",
    "\n",
    "    # wandb.log({'Train Loss': train_loss}, step=e)\n",
    "    # wandb.log({'Train Acc': train_acc}, step=e)\n",
    "    # wandb.log({'Test Loss': test_loss}, step=e)\n",
    "    # wandb.log({'Test Acc': test_acc}, step=e)\n",
    "    # wandb.log({'lr': lr}, step=e)\n",
    "\n",
    "    if e in lr_schedule and decay:\n",
    "        lr *= 0.1\n",
    "        optimizer = SGD(model, lr=lr)\n",
    "        # optimizer.zero_grad()   should we implement zero_grad()?\n",
    "\n",
    "# wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "44bc79bdedc951859a4620ce4f5a740abfa1bf27d20da6af0e4010c444744bef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
